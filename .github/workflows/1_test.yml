name: Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * *"
  push:
    branches: ["main"]
    tags:
      - "*.*.*"
    paths:
      - "examples/**"
      - "fast_healthchecks/**"
      - "tests/**"
      - ".pre-commit-config.yaml"
      - "pyproject.toml"
      - "uv.lock"
  pull_request:
    paths:
      - "examples/**"
      - "fast_healthchecks/**"
      - "tests/**"
      - ".pre-commit-config.yaml"
      - "pyproject.toml"
      - "uv.lock"

concurrency:
  group: check-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:

  pre-commit:
    runs-on: ubuntu-latest
    if: github.event.repository.fork == false
    steps:

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd

      - name: Set up Python 3.10
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405
        with:
          python-version: '3.10'

      - name: Install uv
        uses: astral-sh/setup-uv@eac588ad8def6316056a12d4907a9d4d84ff7a3b
        with:
          enable-cache: true
          cache-python: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Restore .venv cache (pre-commit)
        uses: actions/cache/restore@v4
        with:
          path: .venv
          key: venv-precommit-${{ runner.os }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}

      - name: Install the project
        run: uv sync --all-extras --dev

      - name: Save .venv cache (pre-commit)
        uses: actions/cache/save@v4
        with:
          path: .venv
          key: venv-precommit-${{ runner.os }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}

      - name: Run pre-commit (uv-managed)
        run: uv run --no-sync --with pre-commit-uv pre-commit run --show-diff-on-failure --color=always --all-files
        env:
          SKIP: "detect-aws-credentials,no-commit-to-branch"

  audit:
    needs: [pre-commit]
    name: pip-audit
    runs-on: ubuntu-latest
    if: github.event.repository.fork == false
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd

      - name: Install uv
        uses: astral-sh/setup-uv@eac588ad8def6316056a12d4907a9d4d84ff7a3b
        with:
          enable-cache: true
          cache-python: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python 3.10
        run: uv python install 3.10

      - name: Install project dependencies
        run: uv sync --group=dev --all-extras

      - name: Run pip-audit
        run: uv run pip-audit

  tests:
    needs: [pre-commit]
    name: ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    if: github.event.repository.fork == false
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.14"
          - "3.13"
          - "3.12"
          - "3.11"
          - "3.10"
        os:
          - ubuntu-latest
          - windows-latest
    env:
      PYTHON: ${{ matrix.python-version }}
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd
        with:
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@eac588ad8def6316056a12d4907a9d4d84ff7a3b
        with:
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-python: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Add .local/bin to Windows PATH
        if: runner.os == 'Windows'
        shell: bash
        run: echo "$USERPROFILE/.local/bin" >> $GITHUB_PATH

      - name: Install make (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          choco install make -y
          echo "C:\ProgramData\chocolatey\bin" >> $env:GITHUB_PATH

      # Avoid uv reparse point error 4394 on Windows when cache restores Python 3.13.x
      - name: Clear Python install dir (Windows)
        if: runner.os == 'Windows'
        shell: bash
        run: rm -rf "${UV_PYTHON_INSTALL_DIR:-}" 2>/dev/null || true

      - name: Set up Python
        shell: bash
        run: uv python install ${{ matrix.python-version }}

      - name: Copy .env from example
        shell: bash
        run: cp .env.example .env

      - name: Restore Docker Compose images
        id: restore-compose-cache
        uses: actions/cache/restore@v4
        with:
          path: .cache/docker-compose
          key: compose-images-v2-${{ runner.os }}-${{ hashFiles('docker-compose.yml', '.env.example') }}

      - name: Load cached Docker images (Ubuntu)
        if: runner.os == 'Linux'
        run: |
          if [ -f .cache/docker-compose/images.tar ]; then
            docker load -i .cache/docker-compose/images.tar
          fi

      # Uses release tag: ref by SHA has no prebuilt index.mjs (Kotlin/JS action)
      - name: Set up WSL with Ubuntu (Windows)
        id: setup-wsl
        if: runner.os == 'Windows'
        uses: Vampire/setup-wsl@v6.0.0
        with:
          distribution: Ubuntu-22.04

      - name: Start Docker services in WSL
        if: runner.os == 'Windows'
        shell: wsl-bash {0}
        run: |
          cd /mnt/d/a/${{ github.event.repository.name }}/${{ github.event.repository.name }}
          export DEBIAN_FRONTEND=noninteractive
          sudo apt-get update -qq
          sudo apt-get install -y ca-certificates curl
          curl -fsSL https://get.docker.com | sudo sh
          sudo service docker start
          if [ -f .cache/docker-compose/images.tar ]; then
            sudo docker load -i .cache/docker-compose/images.tar
          fi
          sudo docker compose up -d --wait
        timeout-minutes: 10

      - name: Set service hosts to WSL IP (Windows)
        if: runner.os == 'Windows'
        shell: bash
        run: |
          WSL_IP=$(wsl hostname -I 2>/dev/null | awk '{print $1}')
          echo "WSL_HOST=$WSL_IP" >> $GITHUB_ENV
          echo "POSTGRES_HOST=$WSL_IP" >> $GITHUB_ENV
          echo "REDIS_HOST=$WSL_IP" >> $GITHUB_ENV
          echo "RABBITMQ_HOST=$WSL_IP" >> $GITHUB_ENV
          echo "MONGO_HOSTS=$WSL_IP" >> $GITHUB_ENV
          echo "OPENSEARCH_HOSTS=$WSL_IP:9200" >> $GITHUB_ENV
          echo "KAFKA_BOOTSTRAP_SERVERS=$WSL_IP:9094,$WSL_IP:9095" >> $GITHUB_ENV
          # Ports for "Wait for WSL services" (from .env / docker-compose)
          for key in POSTGRES_PORT REDIS_PORT RABBITMQ_PORT MONGO_PORT; do
            val=$(grep -E "^${key}=" .env 2>/dev/null | cut -d= -f2-)
            [ -z "$val" ] && case $key in POSTGRES_PORT) val=5432;; REDIS_PORT) val=6379;; RABBITMQ_PORT) val=5672;; MONGO_PORT) val=27017;; esac
            echo "${key}=${val}" >> $GITHUB_ENV
          done
          echo "OPENSEARCH_PORT=9200" >> $GITHUB_ENV
          echo "KAFKA_PORT=9094" >> $GITHUB_ENV
          # Integration app reads DSNs from env; override so readiness checks reach WSL services
          for key in POSTGRES_DSN REDIS_DSN RABBITMQ_DSN MONGO_DSN; do
            val=$(grep -E "^${key}=" .env 2>/dev/null | cut -d= -f2- | sed "s/localhost/$WSL_IP/g")
            [ -n "$val" ] && echo "${key}=$val" >> $GITHUB_ENV
          done

      # Wait until Windows host can reach each WSL service (docker --wait is inside WSL; host visibility can lag)
      - name: Wait for WSL services reachable from Windows
        if: runner.os == 'Windows'
        shell: bash
        run: |
          uv run python -c "
          import os, socket, time
          host = os.environ.get('WSL_HOST', '')
          if not host:
              raise SystemExit('WSL_HOST not set')
          # Ports from .env / docker-compose: Postgres, Redis, RabbitMQ, Mongo, OpenSearch, Kafka
          ports = [
              int(os.environ.get('POSTGRES_PORT', 5432)),
              int(os.environ.get('REDIS_PORT', 6379)),
              int(os.environ.get('RABBITMQ_PORT', 5672)),
              int(os.environ.get('MONGO_PORT', 27017)),
              int(os.environ.get('OPENSEARCH_PORT', 9200)),
              int(os.environ.get('KAFKA_PORT', 9094)),
          ]
          for attempt in range(30):
              try:
                  for p in ports:
                      s = socket.create_connection((host, p), timeout=2)
                      s.close()
                  print('All services reachable.')
                  raise SystemExit(0)
              except OSError:
                  pass
              time.sleep(2)
          raise SystemExit('Timeout waiting for WSL services')
          "

      - name: Print Python DSN env vars (diagnostic)
        if: runner.os == 'Windows'
        shell: bash
        run: |
          echo "--- Python DSN env (diagnostic) ---"
          uv run python -c "
          import os
          for key in ['POSTGRES_DSN', 'REDIS_DSN', 'RABBITMQ_DSN', 'MONGO_DSN', 'OPENSEARCH_HOSTS', 'KAFKA_BOOTSTRAP_SERVERS']:
              print(f'{key}:', os.environ.get(key, 'NOT_SET'))
          "
          echo "------------------------------------"

      - name: Run all tests
        shell: bash
        env:
          DOCKER_SERVICES_UP: ${{ runner.os == 'Windows' && '1' || '' }}
          # Diagnostic logging (helps diagnose Windows readiness 503s)
          PYTHONWARNINGS: always
          LOG_LEVEL: DEBUG
          FASTHEALTHCHECKS_LOG_LEVEL: DEBUG
        run: make tests-all

      # Use config --images (names/tags); images -q yields IDs that docker save rejects on some daemons
      - name: Save Docker Compose images (Ubuntu)
        if: always() && runner.os == 'Linux' && matrix.python-version == '3.13'
        run: |
          mkdir -p .cache/docker-compose
          IMAGES=$(docker compose config --images 2>/dev/null)
          if [ -n "$IMAGES" ]; then
            echo "$IMAGES" | xargs docker save -o .cache/docker-compose/images.tar
          fi

      - name: Save Docker Compose images (Windows WSL)
        if: always() && runner.os == 'Windows' && matrix.python-version == '3.13' && steps.setup_wsl.outcome == 'success'
        shell: wsl-bash {0}
        run: |
          cd /mnt/d/a/${{ github.event.repository.name }}/${{ github.event.repository.name }}
          mkdir -p .cache/docker-compose
          IMAGES=$(sudo docker compose config --images 2>/dev/null)
          echo "docker compose config --images: ${IMAGES:-(empty)}"
          if [ -n "$IMAGES" ]; then
            echo "$IMAGES" | xargs sudo docker save -o .cache/docker-compose/images.tar
          fi

      - name: Verify Docker image cache content (diagnostic)
        if: always() && runner.os == 'Windows' && matrix.python-version == '3.13'
        shell: bash
        run: |
          echo "--- .cache/docker-compose ---"
          ls -la .cache/docker-compose 2>/dev/null || true
          echo "--- images.tar size ---"
          du -sh .cache/docker-compose/images.tar 2>/dev/null || true
          echo "--- first entries in images.tar ---"
          tar -tf .cache/docker-compose/images.tar 2>/dev/null | head -20 || true

      - name: Check Docker images cache size
        id: docker_cache_size
        if: always() && matrix.python-version == '3.13'
        shell: bash
        run: |
          SIZE=0
          if [ -f .cache/docker-compose/images.tar ]; then
            SIZE=$(uv run python -c "import os; print(os.path.getsize('.cache/docker-compose/images.tar'))")
          fi
          echo "size=$SIZE" >> $GITHUB_OUTPUT
          if [ "$SIZE" -gt 1000000 ] 2>/dev/null; then
            echo "valid=true" >> $GITHUB_OUTPUT
          else
            echo "valid=false" >> $GITHUB_OUTPUT
          fi
          echo "images.tar size: $SIZE bytes (valid for cache: $([ "$SIZE" -gt 1000000 ] 2>/dev/null && echo true || echo false))"

      - name: Cache Docker Compose images
        if: always() && matrix.python-version == '3.13' && steps.docker_cache_size.outputs.valid == 'true'
        uses: actions/cache/save@v4
        continue-on-error: true
        with:
          path: .cache/docker-compose
          key: compose-images-v2-${{ runner.os }}-${{ hashFiles('docker-compose.yml', '.env.example') }}

      - name: Stop Docker services in WSL
        if: always() && runner.os == 'Windows' && steps.setup_wsl.outcome == 'success'
        shell: wsl-bash {0}
        run: |
          cd /mnt/d/a/${{ github.event.repository.name }}/${{ github.event.repository.name }}
          sudo docker compose down --remove-orphans --volumes

      - name: Generate coverage XML for Codecov
        shell: bash
        run: uv run coverage xml
